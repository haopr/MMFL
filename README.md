#  A Survey of Multimodal Federated Learning: Background, Applications, and Perspectives

This repository provides a comprehensive collection of papers focused on **Multimodal Federated Learning (MMFL)**, with the primary researches already discussed in our latest review. This repository will continue to be updated, and we welcome you to give it a STAR‚≠êÔ∏è.



***Multimodal Federated Learning*** is a collaborative training process involving multiple clients, each with diverse modality settings and data, conducting learning tasks without disclosing their local raw data. 



![](\Fig1.jpg)



**Table of Contents**

- [Survey](#survey)
- [Unifying Achitectures](#Unifying-Achitectures)
- [Applications](#Applications)
- [Multimodal Datasets](#Multimodal-Datasets)



##  Survey



| Title                                                        | Authors                                                      | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **A Survey of Multimodal Federated Learning: Background, Applications, and Perspectives** | H Pan, XL Zhao, LP He, YC Shi, XG Lin (2024)                 | [PUB](https://link.springer.com/article/10.1007/s00530-024-01422-9) |
| Multimodal Federated Learning: A Survey                      | L Che, J Wang, Y Zhou, F Ma (2023)                           | [PUB](https://www.mdpi.com/1424-8220/23/15/6986)             |
| Federated Learning on Multimodal Data: A Comprehensive Survey | YM Lin, Y Gao, MG Gong, SJ Zhang, YQ Zhang, ZY Li (2023)     | [PUB](https://link.springer.com/article/10.1007/s11633-022-1398-0) |
| Multimodal Federated Learning in Healthcare: a Review        | J Thrasher, A Devkota, P Siwakotai, R Chivukula, P Poudel, C Hu, B Bhattarai, P Gyawali (2023) | [arXiv](https://arxiv.org/abs/2310.09650)                    |
| A Survey of Advances in Multimodal Federated Learning with Applications | G Barry, E Konyar, B Harvill, C Johnstone (2024)             | [PUB](https://link.springer.com/chapter/10.1007/978-3-031-53092-0_15) |



##  Unifying Achitectures



| Title                                                        | Authors                                                      | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| FedMSplit: Correlation-Adaptive Federated Multi-Task Learning across Multimodal Split Networks | J Chen, A Zhang (KDD 2022)                                   | [PUB](https://dl.acm.org/doi/abs/10.1145/3534678.3539384)    |
| FedMultimodal: A Benchmark For Multimodal Federated Learning | T Feng, D Bose, T Zhang, R Hebbar, A Ramakrishna, R Gupta, M Zhang, S Avestimehr, S Narayanan (2023) | [PUB](https://dl.acm.org/doi/abs/10.1145/3580305.3599825)    |
| A Multi-Modal Vertical Federated Learning Framework Based on Homomorphic Encryption | M Gong, Y Zhang, Y Gao, AK Qin, Y Wu, S Wang, Y Zhang (2023) | [PUB](https://ieeexplore.ieee.org/abstract/document/10348546) |
| FedSea: Federated Learning via Selective Feature Alignment for Non-IID Multimodal Data | M Tan, Y Feng, L Chu, J Shi, R Xiao, H Tang, J Yu (2023)     | [PUB](https://ieeexplore.ieee.org/abstract/document/10345705/) |
| On Disentanglement of Asymmetrical Knowledge Transfer for Modality-Task Agnostic Federated Learning | J Chen, A Zhang (AAAI 2024)                                  | [PUB](https://ojs.aaai.org/index.php/AAAI/article/view/29010) |
| Adaptive Hyper-graph Aggregation for Modality-Agnostic Federated Learning | F Qi, S Li (CVPR 2024)                                       | [PUB](https://openaccess.thecvf.com/content/CVPR2024/html/Qi_Adaptive_Hyper-graph_Aggregation_for_Modality-Agnostic_Federated_Learning_CVPR_2024_paper.html) |
| Robust multimodal federated learning for incomplete modalities | S Yu, J Wang, W Hussein, PCK Hung (2024)                     | [PUB](https://www.sciencedirect.com/science/article/pii/S0140366423004395) |
| Communication-Efficient Multimodal Federated Learning: Joint Modality and Client Selection | L Yuan, DJ Han, S Wang, D Upadhyay, C G. Brinton (2024)      | [arXiv](https://arxiv.org/abs/2401.16685)                    |



##  Applications



###  üèÉ‚Äç‚ôÇÔ∏èHuman Activity Recognition

 

**A unified framework for multi-modal federated learning**

*B Xiong, X Yang, F Qi, C Xu*

Neurocomputing, 202204 [PUB](https://www.sciencedirect.com/science/article/pii/S0925231222000820)



**Multimodal federated learning on iot data**

*Y Zhao, P Barnaghi, H Haddadi*

IoTDI, 202205 [PUB](https://ieeexplore.ieee.org/abstract/document/9797401)



**Cross-modal federated human activity recognition via modality-agnostic and modality-specific representation learning**

*X Yang, B Xiong, Y Huang, C Xu*

AAAI, 2022 [PUB](https://ojs.aaai.org/index.php/AAAI/article/view/20213)



**Towards optimal multi-modal federated learning on non-iid data with hierarchical gradient blending**

*S Chen, B Li*

INFOCOM, 2022 [PUB](https://ieeexplore.ieee.org/abstract/document/9796724)



**FL-FD: Federated learning-based fall detection with multimodal data fusion**

*P Qi, D Chiaro, F Piccialli* 

Information Fusion, 202311 [PUB](https://www.sciencedirect.com/science/article/pii/S1566253523002063)



**Cross-Modal Federated Human Activity Recognition**

*X Yang, B Xiong, Y Huang, C Xu*

IEEE Transactions on Pattern Analysis and Machine Intelligence, 202402 [PUB](https://ieeexplore.ieee.org/abstract/document/10440498)



**FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal Federated Learning**

*HQ Le, MNH Nguyen, CM Thwal, Y Qiao, C Zhang, CS Hong*

arXiv, 2023 [arXiv](https://arxiv.org/abs/2307.13214)



### üë©üèø‚Äç‚öïMedical Diagnosis



**Multimodal melanoma detection with federated learning**

*BLY Agbley, J Li, AU Haq, EK Bankas, S Ahmad, IO Agyemang, D Kulevome, WD Ndiaye, B Cobbinah, S Latipova*

ICCWAMTIP, 202112 [PUB](https://ieeexplore.ieee.org/abstract/document/9674116)



**Harmony: Heterogeneous multi-modal federated learning through disentangled model training**

*X Ouyang, Z Xie, H Fu, S Cheng, L Pan, N Ling, G Xing, J Zhou, J Huang*

MobiSys, 2023 [PUB](https://dl.acm.org/doi/abs/10.1145/3581791.3596844)



**A federated learning system with data fusion for healthcare using multi-party computation and additive secret sharing**

*T Muazu, Y Mao, AU Muhammad, M Ibrahim, UMM Kumshe, O Samuel*

Computer Communications, 202402 [PUB](https://www.sciencedirect.com/science/article/pii/S0140366424000069)



**Medical report generation based on multimodal federated learning**

*J Chen, R Pan*

Computerized Medical Imaging and Graphics, 202404 [PUB](https://www.sciencedirect.com/science/article/pii/S0895611124000193)



**Federated Modality-Specific Encoders and Multimodal Anchors for Personalized Brain Tumor Segmentation**

*Q Dai, D Wei, H Liu, J Sun, L Wang, Y Zheng*

AAAI, 2024 [PUB](https://ojs.aaai.org/index.php/AAAI/article/view/27909)



###  üîçÔ∏èCross-modal Retrieval

 

**FedCMR: Federated cross-modal retrieval**

*L Zong, Q Xie, J Zhou, P Wu, X Zhang, B Xu*

SIGIR, 2021 [PUB](https://dl.acm.org/doi/abs/10.1145/3404835.3462989)



**Multimodal Federated Learning via Contrastive Representation Ensemble**

*Q Yu, Y Liu, Y Wang, K Xu, J Liu*

ICLR, 2023 [PUB](https://openreview.net/forum?id=Hnk1WRMAYqg)



### üí¨Visual Question Answer

 

**Think locally, act globally: Federated learning with local and global representations**

*PP Liang, T Liu, L Ziyin, NB Allen, RP Auerbach, D Brent, R Salakhutdinov, LP Morency*

NeurIPS, 2019 [arXiv](https://arxiv.org/abs/2001.01523)



**Federated learning for vision-and-language grounding problems**

*F Liu, X Wu, S Ge, W Fan, Y Zou*

AAAI, 2020 [PUB](https://ojs.aaai.org/index.php/AAAI/article/view/6824)



**Multimodal Federated Learning with Missing Modality via Prototype Mask and Contrast**

*G Bao, Q Zhang, D Miao, Z Gong, L Hu*

arXiv, 2024 [arXiv](https://arxiv.org/abs/2312.13508)



### ü§£Emotion Recognition

 

**Federated Meta-Learning for Emotion and Sentiment Aware Multi-modal Complaint Identification**

*A Singh, S Chandrasekar, S Saha, T Sen*

EMNLP, 2023 [PUB](https://aclanthology.org/2023.emnlp-main.999/)



**Enhancing Emotion Recognition through Federated Learning: A Multimodal Approach with Convolutional Neural Networks**

*N Simiƒá, S Suziƒá, N Milo≈°eviƒá, V Stanojev, T Nosek, B Popoviƒá, D Bajoviƒá* 

Applied Sciences, 202402 [PUB](https://www.mdpi.com/2076-3417/14/4/1325)



**FedCMD: A Federated Cross-Modal Knowledge Distillation for Drivers Emotion Recognition**

*S Bano, N Tonellotto, P Cassar√†, A Gotta*

ACM Transactions on Intelligent Systems and Technology, 202405 [PUB](https://dl.acm.org/doi/full/10.1145/3650040)



### üßô‚Äç‚ôÇÔ∏èPrompt Learning and Model Finetuning

 

**Pfedprompt: Learning personalized prompt for vision-language models in federated learning**

*T Guo, S Guo, J Wang*

WWW, 2023 [PUB](https://dl.acm.org/doi/abs/10.1145/3543507.3583518)



**Global and Local Prompts Cooperation via Optimal Transport for Federated Learning**

*H Li, W Huang, J Wang, Y Shi*

CVPR, 2024 [arXiv](https://arxiv.org/abs/2403.00041)



**Feddat: An approach for foundation model finetuning in multi-modal heterogeneous federated learning**

*H Chen, Y Zhang, D Krompass, J Gu, V Tresp*

AAAI, 2024 [PUB](https://ojs.aaai.org/index.php/AAAI/article/view/29007)



### üì°Internet of Things

 

**Fedfusion: Manifold driven federated learning for multi-satellite and multi-modality fusion**

*DX Li, W Xie, Y Li, L Fang*

Geoscience and Remote Sensing, 2023 [PUB](https://ieeexplore.ieee.org/abstract/document/10342879)



**Autofed: Heterogeneity-aware federated multimodal learning for robust autonomous driving**

*T Zheng, A Li, Z Chen, H Wang, J Luo*

ACM MobiCom, 2023 [PUB](https://dl.acm.org/doi/abs/10.1145/3570361.3592517)



**FedUSL: A Federated Annotation Method for Driving Fatigue Detection based on Multimodal Sensing Data**

*S Yu, Q Yang, J Wang, C Wu*

ACM Transactions on Sensor Networks, 202403 [PUB](https://dl.acm.org/doi/abs/10.1145/3657291)



### üè∑Ô∏èImage Classification



**Fedclip: Fast generalization and personalization for clip in federated learning**

*W Lu, X Hu, J Wang, X Xie*

Data Engineering Bulletin, 2023 [arXiv](https://arxiv.org/abs/2302.13485)



##  Multimodal Datasets

| Datasets          | Paper                                                        | Materials                                                    |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| VQA               | Vqa: Visual question answering                               | [PUB](http://openaccess.thecvf.com/content_iccv_2015/html/Antol_VQA_Visual_Question_ICCV_2015_paper.html) |
| MS COCO           | Microsoft coco: Common objects in context                    | [PUB](https://link.springer.com/chapter/10.1007/978-3-319-10602-1_48) |
| Flickr30k         | Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models | [PUB](http://openaccess.thecvf.com/content_iccv_2015/html/Plummer_Flickr30k_Entities_Collecting_ICCV_2015_paper.html) |
| IEMOCAP           | IEMOCAP: interactive emotional dyadic motion capture database | [PUB](https://link.springer.com/article/10.1007/s10579-008-9076-6) |
| MELD              | Meld: A multimodal multi-party dataset for emotion recognition in conversations | [arXiv](https://arxiv.org/abs/1810.02508)                    |
| CMU-MOSEI         | Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph | [PUB](https://aclanthology.org/P18-1208/)                    |
| Kineics-400       | The Kinetics Human Action Video Dataset                      | [arXiv](https://arxiv.org/abs/1705.06950)                    |
| UCF101            | UCF101: A dataset of 101 human actions classes from videos in the wild | [arXiv](https://arxiv.org/abs/1212.0402)  [HOME](https://www.crcv.ucf.edu/research/data-sets/ucf101/) |
| UR fall detection | Human fall detection on embedded platform using depth maps and wireless accelerometer | [PUB](https://www.sciencedirect.com/science/article/pii/S0169260714003447) [HOME](http://fenix.ur.edu.pl/~mkepski/ds/uf.html) |
| Hateful Memes     | The hateful memes challenge: Detecting hate speech in multimodal memes | [PUB](https://proceedings.neurips.cc/paper/2020/hash/1b84c4cee2b8b3d823b30e2d604b1878-Abstract.html) |
| UR-FUNNY          | UR-FUNNY: A multimodal language dataset for understanding humor | [PUB](https://aclanthology.org/D19-1211/)                    |
| CrisisMMD         | CrisisMMD: Multimodal Twitter Datasets from Natural Disasters | [PUB](https://ojs.aaai.org/index.php/ICWSM/article/view/14983) |
| Vehicle sensor    | Vehicle classification in distributed sensor networks        | [PUB](https://www.sciencedirect.com/science/article/pii/S0743731504000255) |
| MHealth           | mHealthDroid: a novel framework for agile development of mobile health applications | [PUB](https://link.springer.com/chapter/10.1007/978-3-319-13105-4_14) |
| PTB-XL            | PTB-XL, a large publicly available electrocardiography dataset | [HOME](https://physionet.org/content/ptb-xl/1.0.3/)          |
| ModelNet40        | 3D ShapeNets: A Deep Representation for Volumetric Shapes    | [PUB](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Wu_3D_ShapeNets_A_2015_CVPR_paper.html) |



## Citation

If you find the listing and survey useful for your work, please cite the paper:

```
@
```

